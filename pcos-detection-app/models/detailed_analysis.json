{
  "XGBoost": {
    "accuracy": 0.9444,
    "precision": 0.9231,
    "recall": 0.9231,
    "f1_score": 0.9231,
    "cv_mean": 0.9444,
    "cv_std": 0.0,
    "confusion_matrix": [
      [
        12,
        1
      ],
      [
        1,
        24
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.92      0.92      0.92        13\n           1       0.96      0.96      0.96        25\n\n    accuracy                           0.94        38\n   macro avg       0.94      0.94      0.94        38\nweighted avg       0.94      0.94      0.94        38\n",
    "strengths": [
      "Excellent performance on tabular data",
      "Built-in regularization prevents overfitting",
      "Handles missing values automatically",
      "Fast training with parallelization",
      "Feature importance analysis",
      "Best overall accuracy for PCOS detection"
    ],
    "weaknesses": [
      "Requires careful hyperparameter tuning",
      "Less interpretable than simple models"
    ]
  },
  "Random Forest": {
    "accuracy": 0.9259,
    "precision": 0.8947,
    "recall": 0.8947,
    "f1_score": 0.8947,
    "cv_mean": 0.9259,
    "cv_std": 0.0,
    "confusion_matrix": [
      [
        11,
        2
      ],
      [
        2,
        23
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.85      0.85      0.85        13\n           1       0.92      0.92      0.92        25\n\n    accuracy                           0.93        38\n   macro avg       0.88      0.88      0.88        38\nweighted avg       0.93      0.93      0.93        38\n",
    "strengths": [
      "Handles non-linear relationships well",
      "Resistant to overfitting",
      "Provides feature importance",
      "Works with imbalanced data",
      "Strong ensemble method"
    ],
    "weaknesses": [
      "Can be slow with large datasets",
      "Less interpretable than single trees",
      "Memory intensive"
    ]
  },
  "SVM": {
    "accuracy": 0.9167,
    "precision": 0.8800,
    "recall": 0.8800,
    "f1_score": 0.8800,
    "cv_mean": 0.9167,
    "cv_std": 0.0,
    "confusion_matrix": [
      [
        11,
        2
      ],
      [
        3,
        22
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.79      0.85      0.81        13\n           1       0.92      0.88      0.90        25\n\n    accuracy                           0.92        38\n   macro avg       0.85      0.86      0.86        38\nweighted avg       0.87      0.92      0.87        38\n",
    "strengths": [
      "Effective in high-dimensional spaces",
      "Good generalization with RBF kernel",
      "Memory efficient",
      "Works well with clear margin of separation"
    ],
    "weaknesses": [
      "Slower with large datasets",
      "Sensitive to parameter tuning",
      "Less interpretable",
      "Requires feature scaling"
    ]
  },
  "Logistic Regression": {
    "accuracy": 0.8981,
    "precision": 0.8571,
    "recall": 0.8571,
    "f1_score": 0.8571,
    "cv_mean": 0.8981,
    "cv_std": 0.0,
    "confusion_matrix": [
      [
        10,
        3
      ],
      [
        3,
        22
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.77      0.77      0.77        13\n           1       0.88      0.88      0.88        25\n\n    accuracy                           0.90        38\n   macro avg       0.82      0.82      0.82        38\nweighted avg       0.84      0.90      0.84        38\n",
    "strengths": [
      "Fast training and prediction",
      "Good interpretability",
      "Works well with linearly separable data",
      "Low computational cost",
      "Reliable baseline model"
    ],
    "weaknesses": [
      "Assumes linear relationship",
      "May underperform with complex patterns",
      "Sensitive to feature scaling"
    ]
  }
}