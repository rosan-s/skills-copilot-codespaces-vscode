{
  "Logistic Regression": {
    "accuracy": 0.95,
    "precision": 0.9285714285714286,
    "recall": 1.0,
    "f1_score": 0.9629629629629629,
    "cv_mean": 0.96875,
    "cv_std": 0.03423265984407288,
    "confusion_matrix": [
      [
        12,
        2
      ],
      [
        0,
        26
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       1.00      0.86      0.92        14\n           1       0.93      1.00      0.96        26\n\n    accuracy                           0.95        40\n   macro avg       0.96      0.93      0.94        40\nweighted avg       0.95      0.95      0.95        40\n",
    "strengths": [
      "Fast training and prediction",
      "Good interpretability",
      "Works well with linearly separable data",
      "Low computational cost"
    ],
    "weaknesses": [
      "Assumes linear relationship",
      "May underperform with complex patterns",
      "Sensitive to feature scaling"
    ]
  },
  "Random Forest": {
    "accuracy": 0.925,
    "precision": 0.896551724137931,
    "recall": 1.0,
    "f1_score": 0.9454545454545454,
    "cv_mean": 0.9625,
    "cv_std": 0.03061862178478973,
    "confusion_matrix": [
      [
        11,
        3
      ],
      [
        0,
        26
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       1.00      0.79      0.88        14\n           1       0.90      1.00      0.95        26\n\n    accuracy                           0.93        40\n   macro avg       0.95      0.89      0.91        40\nweighted avg       0.93      0.93      0.92        40\n",
    "strengths": [
      "Handles non-linear relationships well",
      "Resistant to overfitting",
      "Provides feature importance",
      "Works with imbalanced data"
    ],
    "weaknesses": [
      "Can be slow with large datasets",
      "Less interpretable than single trees",
      "Memory intensive"
    ]
  },
  "SVM": {
    "accuracy": 0.95,
    "precision": 0.9285714285714286,
    "recall": 1.0,
    "f1_score": 0.9629629629629629,
    "cv_mean": 0.975,
    "cv_std": 0.023385358667337135,
    "confusion_matrix": [
      [
        12,
        2
      ],
      [
        0,
        26
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       1.00      0.86      0.92        14\n           1       0.93      1.00      0.96        26\n\n    accuracy                           0.95        40\n   macro avg       0.96      0.93      0.94        40\nweighted avg       0.95      0.95      0.95        40\n",
    "strengths": [
      "Effective in high-dimensional spaces",
      "Good generalization with RBF kernel",
      "Memory efficient",
      "Works well with clear margin of separation"
    ],
    "weaknesses": [
      "Slower with large datasets",
      "Sensitive to parameter tuning",
      "Less interpretable",
      "Requires feature scaling"
    ]
  },
  "XGBoost": {
    "accuracy": 0.825,
    "precision": 0.8518518518518519,
    "recall": 0.8846153846153846,
    "f1_score": 0.8679245283018868,
    "cv_mean": 0.95,
    "cv_std": 0.0375,
    "confusion_matrix": [
      [
        10,
        4
      ],
      [
        3,
        23
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       0.77      0.71      0.74        14\n           1       0.85      0.88      0.87        26\n\n    accuracy                           0.82        40\n   macro avg       0.81      0.80      0.80        40\nweighted avg       0.82      0.82      0.82        40\n",
    "strengths": [
      "Excellent performance on tabular data",
      "Built-in regularization prevents overfitting",
      "Handles missing values automatically",
      "Fast training with parallelization",
      "Feature importance analysis"
    ],
    "weaknesses": [
      "Requires careful hyperparameter tuning",
      "Can overfit on small datasets",
      "Less interpretable than simple models"
    ]
  },
  "K-Nearest Neighbors": {
    "accuracy": 0.95,
    "precision": 0.9285714285714286,
    "recall": 1.0,
    "f1_score": 0.9629629629629629,
    "cv_mean": 0.96875,
    "cv_std": 0.01976423537605237,
    "confusion_matrix": [
      [
        12,
        2
      ],
      [
        0,
        26
      ]
    ],
    "classification_report": "              precision    recall  f1-score   support\n\n           0       1.00      0.86      0.92        14\n           1       0.93      1.00      0.96        26\n\n    accuracy                           0.95        40\n   macro avg       0.96      0.93      0.94        40\nweighted avg       0.95      0.95      0.95        40\n",
    "strengths": [
      "Simple and intuitive algorithm",
      "No training phase required",
      "Works well with local patterns",
      "Naturally handles multi-class problems",
      "Non-parametric - no assumptions about data distribution"
    ],
    "weaknesses": [
      "Slow prediction with large datasets",
      "Sensitive to feature scaling",
      "Requires choosing optimal k value",
      "Curse of dimensionality",
      "Memory intensive for large datasets"
    ]
  }
}